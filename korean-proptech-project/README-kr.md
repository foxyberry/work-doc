# Rebuild Analytics (리빌드 애널리틱스)

> **재개발/재건축 사업성 분석 플랫폼** - 지도 기반 폴리곤 선택으로 정비사업 투자 의사결정 지원

---

## 프로젝트 개요

### 개요

리빌드 애널리틱스는 지도 기반의 폴리곤 선택 기능을 통해 재개발/재건축 예정지 또는 관심 지역을 직관적으로 설정하고, 해당 지역의 사업성 분석 결과를 즉시 확인할 수 있는 부동산 데이터 분석 서비스입니다.
사용자는 지도를 클릭해 경계를 지정하기만 하면, 해당 지역의 토지 조서와 사업성 분석 결과가 자동으로 생성됩니다. 각 지역에 적용되는 노후도 조건과 부동산 지수(거래건수, 노후 평균, 평균 분양가)를 기반으로 종합적인 인사이트를 제시하며, 조건을 바꿔가며 다양한 손익 시뮬레이션을 즉각적으로 확인할 수 있습니다.


### 핵심 가치

- **지도 기반 폴리곤 검색**: 지도 위에서 폴리곤을 그려 재개발/재건축 예정지를 즉시 설정
- **실시간 사업성 분석**: 토지 조서, 노후도 조건, 부동산 지수를 기반으로 종합적인 사업성 분석 결과 자동 생성
- **손익 시뮬레이션**: 다양한 조건을 조합하여 즉각적인 손익 시뮬레이션 확인 가능
- **분석 결과 다운로드**: Excel 형태의 분석 보고서를 즉시 생성하여 제3자와 손쉽게 공유
- **AI 기반 데이터 해석**: LLM을 통해 시각화 그래프를 자연어로 자동 설명하여 비전문가도 쉽게 이해 가능
- **정비구역 데이터 통합**: 서울시 의제 처리된 정비구역, 재정비촉진지구, 도시개발구역 리스트 반영

### 제품/서비스 경쟁력

리빌드 애널리틱스는 정비사업에 특화된 데이터 분석 도구로, 사용자가 지도 상에서 관심 지역을 폴리곤 형태로 자유롭게 지정하면 해당 구역의 사업성 분석 결과를 즉시 확인할 수 있습니다. 이 과정에서 활용된 기초 데이터(토지정보, 노후도, 실거래가, 분양가 등)를 함께 제공하고, 분석 결과는 엑셀 파일로 다운로드할 수 있어, 사용자가 자체적으로 다양한 조건을 시뮬레이션하거나 외부 전문가와 쉽게 공유할 수 있도록 구성되어 있습니다.

**미래 가치 중심의 의사결정 지원**

리빌드 애널리틱스는 기존의 시세 중심 평가에서 벗어나, 미래 가치를 중심으로 의사결정을 지원하는 점에서 차별성을 갖고 있습니다. 도시 노후화가 더욱 진행될 것으로 예상되며, 지역의 가치를 판단할 때 단순히 현재의 매매가나 공시지가만으로는 충분하지 않습니다. 정비사업 가능성, 재개발 이후의 자산 가치, 비례율 등 미래 사업성을 함께 고려해야 보다 정밀한 가치 평가가 가능해집니다.

리빌드 애널리틱스는 이러한 관점을 반영해, 현재의 기초 데이터뿐 아니라 향후 개발 잠재력과 다양한 시나리오에 따른 손익 시뮬레이션을 함께 제공함으로써, 사용자가 미래 지향적인 판단을 내릴 수 있도록 돕고 있습니다.

**대상 사용자**

리빌드 애널리틱스는 전문가, 기업 투자자, 일반 투자자 모두를 위한 사업성 검토 도구로, 정보 비대칭이 심한 정비사업 분야에서 의사결정의 정확성과 효율성을 향상시키고자 합니다.

### 진행 중인 실험

- **LLM 기반 그래프 자동 설명**: 분석 결과의 시각화 그래프를 LLM을 통해 자동 설명하는 기능 실험 중. 사용자가 이해하기 어려운 지표나 데이터 해석을 자연어로 제공
- **MCP(Model Context Protocol) 연동**: 직접 개발한 API를 MCP로 연결하여 Claude 클라이언트와 연동하는 실험 진행 중. 유저가 특정 사업지의 분석 결과를 보다 쉽게 이해하고, 챗봇 투자 상담으로 확장 가능성 검토 중

---

## Tech Stack

```
Backend       Kotlin, Java 17, Spring Boot 3.3.2, FastAPI
Data          Elasticsearch 8.8, Redis, PostgreSQL
AI/ML         LangChain, OpenAI GPT-4, MCP (Model Context Protocol)
Auth          Keycloak 23.0, OAuth2, JWT, RBAC
DevOps        Docker, GitHub Actions, Self-hosted Runner
Document      Apache POI (Excel), OpenHTMLtoPDF, iText7
```

---

## 핵심 도전 과제와 해결 과정

### 1. 정부 공공데이터의 비정형/대용량 처리

**문제 상황:**
- 정부에서 제공하는 CSV 파일은 수십만~수백만 건의 레코드
- 파일마다 인코딩, 컬럼 구조, 데이터 형식이 다름
- 단순 파싱으로는 메모리 부족 발생

**해결 방법:**
- OpenCSV 기반 커스텀 파서 구축, 스트리밍 방식으로 메모리 효율화
- 데이터 유형별(D003, D006, D151 등) 전용 매퍼 클래스 설계
- Elasticsearch Bulk API로 배치 인덱싱, 처리 속도 최적화
- 데이터 정합성 검증 로직 추가로 누락/오류 데이터 필터링

### 2. 복잡한 인증/인가 체계 구축

**문제 상황:**
- 게스트, 일반 사용자, 프리미엄 사용자, 관리자 등 다양한 역할 필요
- AI 서비스(Python)와 메인 API(Kotlin) 간 인증 공유 필요
- MCP 서버에서도 동일한 인증 체계 사용 필요

**해결 방법:**
- Keycloak을 IdP로 도입, OAuth 2.0 + OIDC 표준 준수
- Spring Security와 Keycloak 연동으로 RBAC 구현
- FastAPI용 JWT 검증 미들웨어 직접 구현
- MCP 서버에 세션 토큰 캐싱으로 반복 인증 최소화

**RBAC 구조:**
```
guest      → Basic API Access
user       → Standard Features
super_user → Premium (Excel, PDF Export)
admin      → Administrative APIs
```

### 3. 여러 환경의 통합 로그 관리

**문제 상황:**
- Dev, Stage, Prod 환경의 로그가 각각 분산
- 장애 발생 시 여러 서버에 접속해서 로그 확인 필요
- 텍스트 로그로는 검색/분석 어려움

**해결 방법:**
- ELK Stack(Elasticsearch + Logstash + Kibana) 직접 구축
- Logstash Logback Encoder로 JSON 구조화 로그 전송
- 환경별 TCP 포트 분리 (dev:4560, prod:4561, stage:4562)
- 환경별 인덱스 패턴으로 Kibana에서 통합 검색 가능

### 4. AI 서비스와 기존 시스템 통합

**문제 상황:**
- GPT를 활용한 토지 분석 기능 추가 필요
- 기존 Spring Boot API와 자연스럽게 연동해야 함
- Claude Desktop에서도 직접 데이터 조회 가능하게 하고 싶음

**해결 방법:**
- LangChain + FastAPI로 별도 AI 서비스 구축
- LangServe로 Chain을 REST API로 노출
- MCP(Model Context Protocol) 서버 구현으로 Claude Desktop 연동
- LangSmith 연동으로 모든 LLM 호출 추적 및 디버깅

### 5. Multi-Environment 배포 자동화

**문제 상황:**
- 클라우드가 아닌 개인 서버에서 HTTPS 서비스 필요
- 수동 배포는 실수 가능성 높고 시간 소모

**해결 방법:**
- Let's Encrypt로 무료 SSL 인증서 수동 발급 및 갱신
- GitHub Actions + Self-hosted Runner로 CI/CD 파이프라인 구축
- Git 태그 생성 시 자동 배포 트리거
- PKCS12 Keystore 변환 자동화 (GitHub Secrets 활용)

**환경별 구성:**

| Env | Port | Protocol | 용도 |
|-----|------|----------|------|
| Local | 8080 | HTTP | IDE 개발 |
| Dev | 8080 | HTTP | Docker 테스트 |
| Stage | 9442 | HTTPS | 사전 검증 |
| Prod | 9443 | HTTPS | 운영 (Full Stack + AI) |

---

## 기술 선택의 이유

### Kotlin + Spring Boot
- **선택 이유**: Kotlin + Spring 조합에 대한 경험이 많기 때문에 
- **결과**: 런타임 NullPointerException 거의 발생하지 않음

### Elasticsearch
- **선택 이유**: 한국어 형태소 분석 지원, GeoShape 쿼리로 위치 기반 검색 가능
- **결과**: 수백만 건 데이터에서 밀리초 단위 검색 응답

### Keycloak
- **선택 이유**: OAuth 2.0/OIDC 완전 지원, RBAC 내장, 관리 UI 제공
- **결과**: 복잡한 역할 기반 접근 제어를 설정만으로 구현

### LangChain + MCP
- **선택 이유**: LLM 애플리케이션의 사실상 표준, MCP로 Claude 직접 연동 가능
- **결과**: 프롬프트 관리, 호출 추적, 다양한 클라이언트 지원

---

## 시스템 아키텍처

```
┌─────────────────────────────────────────────────────────────────────┐
│                        Client Applications                          │
└─────────────────────────────────────────────────────────────────────┘
                                   │
                                   ▼
┌─────────────────────────────────────────────────────────────────────┐
│                       Application Layer                             │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────────┐ │
│  │  Spring Boot    │  │  FastAPI        │  │  MCP Server         │ │
│  │  REST API       │  │  AI Service     │  │  Claude 연동        │ │
│  │  (:9443)        │  │  (:8123)        │  │                     │ │
│  └─────────────────┘  └─────────────────┘  └─────────────────────┘ │
└─────────────────────────────────────────────────────────────────────┘
                                   │
                                   ▼
┌─────────────────────────────────────────────────────────────────────┐
│                        Common Modules                               │
│  ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐  │
│  │csv-reader│ │    es    │ │generator │ │  model   │ │  redis   │  │
│  └──────────┘ └──────────┘ └──────────┘ └──────────┘ └──────────┘  │
└─────────────────────────────────────────────────────────────────────┘
                                   │
                                   ▼
┌─────────────────────────────────────────────────────────────────────┐
│                       Infrastructure Layer                          │
│  ┌───────────────────────────┐  ┌───────────────────────────────┐  │
│  │       ELK Stack           │  │       Auth Stack              │  │
│  │  ES │ Logstash │ Kibana   │  │  Keycloak │ PostgreSQL        │  │
│  └───────────────────────────┘  └───────────────────────────────┘  │
│  ┌─────────────────┐  ┌───────────────────────────────────────┐    │
│  │      Redis      │  │       External APIs                   │    │
│  │     (Cache)     │  │  OpenAI │ Map API │ Government Data   │    │
│  └─────────────────┘  └───────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────────┘
```

---

## 프로젝트 구조

```
├── application/          # Spring Boot REST API
├── batch/etl/            # Data Pipeline (Picocli CLI)
├── common/
│   ├── csv-reader/       # Government CSV Parser
│   ├── es/               # Elasticsearch Integration
│   ├── generator/        # Report Engine (PDF, Excel)
│   ├── model/            # Shared DTOs & Entities
│   └── redis/            # Cache Module
├── langchain/            # AI Service (FastAPI + LangChain)
└── mcp-server/           # Model Context Protocol Server
```

---

## 프로젝트 성과

| 항목 | 수치 |
|------|------|
| 총 모듈 수 | 8개 (멀티모듈 Gradle) |
| API 엔드포인트 | 29개 |
| 처리 데이터 | 정부 공공데이터 10종 이상 |
| Docker 서비스 | 6개 (API, AI, Auth, ES, Redis, ELK) |
| 코드 라인 | 30,000줄 이상 |
| 개발/운영 기간 | 1년 이상 (현재 운영 중) |

---

## 적용 기술 요약

| Category | Skills |
|----------|--------|
| **Backend** | Spring Boot, Kotlin, RESTful API, Multi-module Architecture |
| **Data** | Elasticsearch, ETL Pipeline, Data Modeling, GeoShape Query |
| **DevOps** | Docker, CI/CD, Multi-environment Management, SSL/TLS |
| **Security** | OAuth2, JWT, RBAC, Keycloak |
| **AI** | LangChain, OpenAI Integration, MCP, LangSmith |
| **Monitoring** | ELK Stack, Structured Logging, Kibana Dashboard |

---

## API 설계 개요

### API 계층 구조

```
┌─────────────────────────────────────────────────────────────────────┐
│                        Client Layer                                  │
│          Web Client │ Mobile Client │ API Testing Tools             │
└─────────────────────────────────────────────────────────────────────┘
                                   │
                                   ▼
┌─────────────────────────────────────────────────────────────────────┐
│                       Security Layer                                 │
│              CORS Filter │ OAuth2 Resource Server │ JWT              │
└─────────────────────────────────────────────────────────────────────┘
                                   │
                                   ▼
┌─────────────────────────────────────────────────────────────────────┐
│                         API Layer                                    │
│  ┌───────────────┐  ┌───────────────┐  ┌───────────────────────┐   │
│  │  Auth API     │  │  Reports API  │  │  Download API         │   │
│  │  토큰 발급    │  │  토지 분석    │  │  Excel/PDF Export     │   │
│  └───────────────┘  └───────────────┘  └───────────────────────┘   │
│  ┌───────────────┐  ┌───────────────┐  ┌───────────────────────┐   │
│  │  User API     │  │  Data API     │  │  Admin API            │   │
│  │  검색 히스토리│  │  도시계획구역 │  │  통계/관리            │   │
│  └───────────────┘  └───────────────┘  └───────────────────────┘   │
└─────────────────────────────────────────────────────────────────────┘
```

### 주요 API 기능

| API 그룹 | 주요 기능 | 설명 |
|----------|----------|------|
| **Reports API** | 지역별 토지 보고서, 사업성 분석 | GeoShape 쿼리 기반 토지 데이터 조회 |
| **Download API** | Excel/PDF 다운로드 | 분석 결과를 보고서 형태로 내보내기 |
| **User API** | 검색 히스토리, 즐겨찾기 | 사용자별 검색 기록 관리 |
| **Data API** | 도시계획구역 조회 | 서울시 정비구역 데이터 제공 |
| **Admin API** | 사용 통계, 시스템 관리 | 관리자용 대시보드 데이터 |

### 역할 기반 접근 제어 (RBAC)

| 역할 | 기본 API | 프리미엄 기능 | 관리자 기능 |
|------|----------|--------------|------------|
| guest | O | X | X |
| user | O | X | X |
| super_user | O | O (Excel/PDF Export) | X |
| admin | X | X | O |

---

## 인증 시스템 설계

### OAuth 2.0 기반 인증 아키텍처

```
┌─────────────┐     ┌─────────────────┐     ┌─────────────────┐
│   Client    │────▶│  Spring Boot    │────▶│    Keycloak     │
│             │     │  (Resource      │     │  (Identity      │
│             │◀────│   Server)       │◀────│   Provider)     │
└─────────────┘     └─────────────────┘     └─────────────────┘
      │                     │                       │
      │  1. API Request     │  2. JWT Validation    │
      │  + Bearer Token     │                       │
      │                     │  3. Role Extraction   │
      │                     │                       │
      │  4. Response        │                       │
      │◀────────────────────│                       │
```

### 인증 흐름

1. **토큰 발급**: 클라이언트가 Keycloak에 Password Grant 요청
2. **JWT 수신**: Access Token + Refresh Token 수령
3. **API 요청**: Bearer Token과 함께 API 호출
4. **검증**: Spring Security가 JWT 서명 및 만료 검증
5. **권한 확인**: 토큰 내 역할(Role) 기반 접근 제어

### 보안 특징

- **OAuth 2.0 + OIDC** 표준 준수
- **JWT 기반** 무상태(Stateless) 인증
- **역할 기반 접근 제어** (RBAC)
- **다중 서비스 간 인증 공유** (Spring Boot ↔ FastAPI ↔ MCP Server)

---

## 데이터 분석 모델

### 지역별 시세 보정 모델

공시가격과 실제 시장 가격 사이의 간극을 한국부동산원의 아파트 매매가격지수를 활용하여 보정하는 모델을 개발했습니다.

**도입 배경:**
- 공시가격은 연 1회 산정되어 급변하는 시장 상황을 반영하지 못함
- 지역별로 상이한 가격 변동률을 포착하는 데 한계
- 같은 서울 내에서도 서초구(+17.3%)와 도봉구(-14.0%)의 극명한 격차 존재

**핵심 알고리즘:**
```
보정 가중치(W) = (1 ÷ 현실화율) × (현재 매매지수 ÷ 공시가격 기준일 매매지수)
보정 시세 = 공시가격 × W
```

**모델 특징:**
- 공시가격 이후의 순수한 시장 변동분만 보정
- 장기 누적 효과로 인한 가중치 과대 산정 방지
- 지역별 고유의 시장 흐름 반영

**활용 분야:**
- 부동산 자산 포트폴리오 평가
- 담보 가치 평가 및 LTV 산정
- 투자 의사결정 지원

---

## 향후 발전 방향

- Kubernetes 마이그레이션으로 확장성 확보
- RAG(Retrieval-Augmented Generation) 도입으로 AI 분석 고도화
- 실시간 데이터 스트리밍 파이프라인 구축
